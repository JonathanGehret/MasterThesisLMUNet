{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50286ba4-0172-4b82-8328-6f0736e77644",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Concatenate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e378d3e6-99a6-4f27-8845-17f4fc366a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9fa184-9b05-49f4-99a4-a864c3a9c77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071ea8bb-6cfa-463f-a868-8f59680bacce",
   "metadata": {},
   "source": [
    "## Stacking n metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e74292-1716-4694-886c-46f2e33c9b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric_dir=['notebooks/data/100k_nan_mask_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_ai_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_area_cv_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_area_mn_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_area_sd_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_cai_cv_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_cai_mn_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_cai_sd_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_circle_cv_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_circle_mn_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_circle_sd_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_cohesion_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_condent_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_contag_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_core_cv_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_core_mn_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_core_sd_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_dcad_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_dcore_cv_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_dcore_mn_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_dcore_sd_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_division_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_ed_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_ent_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_frac_mn_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_frac_sd_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_iji_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_joinent_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_lpi_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_lsi_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_mesh_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_msidi_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_msiei_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_mutinf_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_ndca_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_np_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_pafrac_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_para_cv_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_para_mn_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_para_sd_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_pd_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_pladj_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_pr_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_prd_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_relmutinf_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_rpr_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_shape_cv_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_shape_mn_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_shape_sd_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_shdi_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_shei_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_sidi_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_siei_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_split_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_ta_5_class_metr/', '1TB_HDD/data_metrics_1tb_02/100k_tca_5_class_metr/', '1TB_HDD/data_metrics_1TB/100k_te_5_class_metr/']\n",
      "len(metric_dir)=57\n"
     ]
    }
   ],
   "source": [
    "# Load names of all metrics to stack\n",
    "metr_names         = pd.read_csv(f'notebooks/data/multi_metrics_66.csv', header=None)\n",
    "#metr_names         = pd.read_csv(f'data/all_metrics_ordered_short.csv', header=None)\n",
    "#metr_names         = pd.read_csv(f'data/all_metrics_ordered.csv', header=None)\n",
    "\n",
    "# # Add directories of every metric to stack to the list metric_dir\n",
    "Some changeups in file names and locations in between, this is to load all of them\n",
    "metric_dir = []\n",
    "for metr in metr_names[0]:\n",
    "    metr = metr[6:]\n",
    "    if  os.path.isdir(f\"notebooks/data/100k_{metr}_5_class_metr/\"):\n",
    "        metric_dir.append(f\"notebooks/data/100k_{metr}_5_class_metr/\")\n",
    "    elif os.path.isdir(f\"1TB_HDD/data_metrics_1TB/100k_{metr}_5_class_metr/\"):\n",
    "        metric_dir.append(f\"1TB_HDD/data_metrics_1TB/100k_{metr}_5_class_metr/\")\n",
    "    elif os.path.isdir(f\"1TB_HDD/data_metrics_1tb_02/100k_{metr}_5_class_metr/\"):\n",
    "        metric_dir.append(f\"1TB_HDD/data_metrics_1tb_02/100k_{metr}_5_class_metr/\")\n",
    "\n",
    "print(f'{metric_dir=}')\n",
    "print(f'{len(metric_dir)=}') # should be 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52ce541-5748-4e8a-aae9-84ae3ac1f5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        metr_10000001.npy\n",
      "1        metr_10021913.npy\n",
      "2        metr_10056455.npy\n",
      "3        metr_10006455.npy\n",
      "4        metr_10003033.npy\n",
      "               ...        \n",
      "99995    metr_10056555.npy\n",
      "99996    metr_10015838.npy\n",
      "99997    metr_10037767.npy\n",
      "99998    metr_10059682.npy\n",
      "99999    metr_10028378.npy\n",
      "Name: 1, Length: 100000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load name table\n",
    "TRAIN_DF         = pd.read_csv('notebooks/data/100k_joinent_5_class_metric_list.csv', header=None) #100k 5 class\n",
    "print(TRAIN_DF[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b63c44-5522-49c1-bf2e-79d7fea21d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory to save stacked metrics in\n",
    "new_dir = 'notebooks/data/100k_5cl_multi_metrics_66/'\n",
    "os.mkdir(new_dir)\n",
    "\n",
    "# Load and stack all of those metrics\n",
    "for file in TRAIN_DF[1]:\n",
    "    metrixs = []\n",
    "    for metric_n in metric_dir:\n",
    "          \n",
    "        # Load metrics\n",
    "        metric_nn = np.load(metric_n + file).astype('float32')\n",
    "        metrixs.append(metric_nn)\n",
    "    \n",
    "    # Stack all into one file\n",
    "    metric_stack = np.stack((metrixs), axis = 2) # her should probaly enter axis = 1 or something\n",
    "    \n",
    "    # Write file to new directory\n",
    "    np.save(new_dir + file, metric_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51034482-977e-4c69-887a-43a216dd6170",
   "metadata": {},
   "source": [
    "## Alternatively: Concatenating 1 to many\n",
    "If there are already stacked metrics, single ones can also concatenated to the existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcba5a66-cc78-4989-aa40-1ce16a005597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        metr_10000001.npy\n",
      "1        metr_10021913.npy\n",
      "2        metr_10056455.npy\n",
      "3        metr_10006455.npy\n",
      "4        metr_10003033.npy\n",
      "               ...        \n",
      "99995    metr_10056555.npy\n",
      "99996    metr_10015838.npy\n",
      "99997    metr_10037767.npy\n",
      "99998    metr_10059682.npy\n",
      "99999    metr_10028378.npy\n",
      "Name: 1, Length: 100000, dtype: object\n",
      "Elapsed time: 476.661 seconds\n"
     ]
    }
   ],
   "source": [
    "# Set directory of already stacked metrics\n",
    "many_dir = 'data/100k_5cl_multi_metrics_7/'\n",
    "\n",
    "# Set directory of new to add metrics\n",
    "to_add_dir = 'data/100k_ndca_5_class_metr/'\n",
    "\n",
    "# Set (and create) directory where to save new stack\n",
    "new_dir = 'data/100k_5cl_multi_metrics_8/'\n",
    "os.mkdir(new_dir)\n",
    "\n",
    "# Load names of all metrics\n",
    "TRAIN_DF         = pd.read_csv('data/100k_joinent_5_class_metric_list.csv', header=None) #100k 5 class\n",
    "print(TRAIN_DF[1])\n",
    "\n",
    "# Load all and concatenate new one\n",
    "for file in TRAIN_DF[1]:\n",
    "    \n",
    "    # Load metrics\n",
    "    metric_many = np.load(many_dir + file).astype('float32')\n",
    "    metric_to_add = np.load(to_add_dir + file).astype('float32')\n",
    "    metric_to_add = np.expand_dims(metric_to_add, axis = 2)\n",
    "        \n",
    "    # Stack all into one file\n",
    "    metric_conc = np.concatenate((metric_many,metric_to_add), axis = 2) # her should probaly enter axis = 1 or something\n",
    "    \n",
    "    # Write file to new directory\n",
    "    np.save(new_dir + file, metric_conc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2589f198-51e0-4e9f-8bcf-040bb6db1caf",
   "metadata": {},
   "source": [
    "## Stack one metric 50 times for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e572ccf-4b92-4fec-bfc0-cff57f9ca189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direcotry of metric to stack\n",
    "metric_dir_01 = 'data/100k_dcad_5_class_metr_f32/'\n",
    "\n",
    "# Directory to save stacked metrics in\n",
    "new_dir = 'data/100k_50_channel_dcad/'\n",
    "os.mkdir(new_dir)\n",
    "\n",
    "# Loop over all metrics and save stack to new dir\n",
    "for file in os.listdir(metric_dir_01):\n",
    "    \n",
    "    # Load metrics\n",
    "    metric_01 = np.load(metric_dir_01 + file)  \n",
    "\n",
    "    # Stack all classeses into one file    \n",
    "    metric_conc = np.stack(( \n",
    "        metric_01, metric_01, metric_01, metric_01, metric_01, \n",
    "        metric_01, metric_01, metric_01, metric_01, metric_01, \n",
    "        metric_01, metric_01, metric_01, metric_01, metric_01, \n",
    "        metric_01, metric_01, metric_01, metric_01, metric_01, \n",
    "        metric_01, metric_01, metric_01, metric_01, metric_01,\n",
    "        metric_01, metric_01, metric_01, metric_01, metric_01, \n",
    "        metric_01, metric_01, metric_01, metric_01, metric_01, \n",
    "        metric_01, metric_01, metric_01, metric_01, metric_01, \n",
    "        metric_01, metric_01, metric_01, metric_01, metric_01, \n",
    "        metric_01, metric_01, metric_01, metric_01, metric_01), axis = 0)\n",
    "    \n",
    "    # Write file to new directory\n",
    "    np.save(new_dir + file, metric_conc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
